{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone 2 - Final Version - Youtube API and search analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "googleapiclient.discovery.Resource"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Youtube (YT) query setup\n",
    "from datetime import datetime\n",
    "today = datetime.today()\n",
    "\n",
    "api_key = 'AIzaSyAZQIsx0XaXIBpBdtl9gfPY_15x99A5EZE'  # tom's API key\n",
    "from apiclient.discovery import build\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "type(youtube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:  ('P7', 'python for Loops') total video extracts: 25\n",
      "Query:  ('P7', 'python for Loops') total video stats: 25\n",
      "Completed output file: P7_stats.xlsx\n"
     ]
    }
   ],
   "source": [
    "# 8 different python related queries to create YT stats and YT video comment extracts\n",
    "#\n",
    "#\n",
    "#query = ('P1', 'python tutorial') \n",
    "#query = ('P2', 'python reading CSV files')\n",
    "#query = ('P3', 'python pandas dataframes')\n",
    "#query = ('P4', 'python lists')\n",
    "#query = ('P5', 'python dictionaries')\n",
    "#query = ('P6', 'python sort functions')\n",
    "query = ('P7', 'python for Loops')\n",
    "#query = ('P8', 'python tuples')\n",
    "\n",
    "#\n",
    "# Set output excel file titles for each query\n",
    "#\n",
    "comments_file = query[0] + '_comments.xlsx'\n",
    "stats_file = query[0] + '_stats.xlsx'\n",
    "# =============================================================================\n",
    "# Search Query Initialisation\n",
    "# =============================================================================\n",
    "\n",
    "query_results = youtube.search().list(\n",
    "        part = 'snippet',\n",
    "        q = query[1],\n",
    "        order = 'relevance',     # You can consider using viewCount\n",
    "        maxResults = 25,         # given the large number of query results, top 25 is fine for our analysis\n",
    "        type = 'video',          # Channels might appear in search results\n",
    "        relevanceLanguage = 'en',\n",
    "        safeSearch = 'moderate',\n",
    "        ).execute()\n",
    "\n",
    "print('Query: ', query,'total video extracts:', len(query_results['items']))\n",
    "#req = youtube.search().list(q='avengers',part='snippet', type='video',maxResults=50)\n",
    "\n",
    "# =============================================================================\n",
    "# Get Video IDs for the YT search response\n",
    "# =============================================================================\n",
    "video_id = []\n",
    "channel = []\n",
    "video_title = []\n",
    "video_desc = []\n",
    "video_age = []\n",
    "search_rank = []\n",
    "x=1\n",
    "for item in query_results['items']:\n",
    "    video_id.append(item['id']['videoId'])\n",
    "    channel.append(item['snippet']['channelTitle'])\n",
    "    video_title.append(item['snippet']['title'])\n",
    "    video_desc.append(item['snippet']['description'])\n",
    "    video_date = datetime.strptime(item['snippet']['publishedAt'],'%Y-%m-%dT%H:%M:%S.%fZ') \n",
    "    date_delta = (today - video_date).days\n",
    "    video_age.append(date_delta//7)\n",
    "    search_rank.append(x)\n",
    "    x += 1\n",
    "print('Query: ', query,'total video stats:', len(video_id))\n",
    "\n",
    "# =============================================================================\n",
    "# Populate to Dataframe\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "\n",
    "output_dict = {\n",
    "        'Query Num': query[0],\n",
    "        'Query': query[1],\n",
    "        'Search Rank': search_rank,\n",
    "        'Channel': channel,\n",
    "        'Video ID': video_id,\n",
    "        'Video Title': video_title,\n",
    "        'Video Description': video_desc,\n",
    "        'Video Age': video_age\n",
    "        }\n",
    "\n",
    "# output_df - this will be merged with the results from the stats query\n",
    "# YT requires 2 separate queries - one for video ids, one for stats\n",
    "#\n",
    "output_df = pd.DataFrame(output_dict, columns = output_dict.keys())\n",
    "#output_df\n",
    "\n",
    "# =============================================================================\n",
    "# Get Video stats\n",
    "# =============================================================================\n",
    "#\n",
    "# Combine video ids into 1 long string to make one block call to YT stats versus individual calls for each video\n",
    "#\n",
    "for i in range(0,len(video_id),50):\n",
    "        video_id_request = ','.join(video_id[i:i+50])\n",
    "\n",
    "#\n",
    "# request stats for all video ids\n",
    "#\n",
    "res_stats = youtube.videos().list(id=video_id_request, part='statistics').execute()\n",
    "\n",
    "# =============================================================================\n",
    "# parse through res_stats for video stats\n",
    "# =============================================================================\n",
    "video_id_stats = []\n",
    "viewCount = []\n",
    "likeCount = []\n",
    "dislikeCount = []\n",
    "commentCount = []\n",
    "for item in res_stats['items']:\n",
    "    #video_id_stats.append(item['id'])\n",
    "    #viewCount.append(item['statistics']['viewCount'])\n",
    "    #likeCount.append(item['statistics']['likeCount'])\n",
    "    #dislikeCount.append(item['statistics']['dislikeCount'])\n",
    "    #commentCount.append(item['statistics']['commentCount'])\n",
    "    \n",
    "    if len(item['statistics']) == 5:\n",
    "        video_id_stats.append(item['id'])\n",
    "        viewCount.append(item['statistics']['viewCount'])\n",
    "        likeCount.append(item['statistics']['likeCount'])\n",
    "        dislikeCount.append(item['statistics']['dislikeCount'])\n",
    "        commentCount.append(item['statistics']['commentCount'])\n",
    "    else:\n",
    "        video_id_stats.append(item['id'])\n",
    "        viewCount.append(item['statistics']['viewCount'])\n",
    "        likeCount.append(0)\n",
    "        dislikeCount.append(0)\n",
    "        commentCount.append(0)\n",
    "#\n",
    "# Output video stats to a dataframe\n",
    "#\n",
    "output_dict_stats = {\n",
    "        'Video ID': video_id_stats,\n",
    "        'view count': viewCount,\n",
    "        'like count': likeCount,\n",
    "        'dislike count': dislikeCount,\n",
    "        'comment count': commentCount\n",
    "        }\n",
    "\n",
    "output_df_stats = pd.DataFrame(output_dict_stats, columns = output_dict_stats.keys())\n",
    "#output_df_stats\n",
    "\n",
    "# Merge video info and video stats into 1 dataframe and output to excel\n",
    "output_df_stats = output_df.merge(output_df_stats, left_on='Video ID', right_on='Video ID', how = 'left')\n",
    "output_df_stats.to_excel(stats_file)\n",
    "print('Completed output file:', stats_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 25/25 [00:09<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed output file: P7_comments.xlsx\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Separate queries to get the most relevant 100 queries for each video\n",
    "#\n",
    "# =============================================================================\n",
    "# Get Comments of Top Videos\n",
    "# =============================================================================\n",
    "video_id_pop = []\n",
    "channel_pop = []\n",
    "video_num_pop = []\n",
    "video_title_pop = []\n",
    "video_desc_pop = []\n",
    "comments_pop = []\n",
    "comment_id_pop = []\n",
    "reply_count_pop = []\n",
    "like_count_pop = []\n",
    "\n",
    "from tqdm import tqdm\n",
    "for i, video in enumerate(tqdm(video_id, ncols = 100)):\n",
    "    response = youtube.commentThreads().list(\n",
    "                    part = 'snippet',\n",
    "                    videoId = video,\n",
    "                    maxResults = 100, # Only take top 100 comments...\n",
    "                    order = 'relevance', #... ranked on relevance\n",
    "                    textFormat = 'plainText',\n",
    "                    ).execute()\n",
    "    \n",
    "    comments_temp = []\n",
    "    comment_id_temp = []\n",
    "    reply_count_temp = []\n",
    "    like_count_temp = []\n",
    "    for item in response['items']:\n",
    "        comments_temp.append(item['snippet']['topLevelComment']['snippet']['textDisplay'])\n",
    "        comment_id_temp.append(item['snippet']['topLevelComment']['id'])\n",
    "        reply_count_temp.append(item['snippet']['totalReplyCount'])\n",
    "        like_count_temp.append(item['snippet']['topLevelComment']['snippet']['likeCount'])\n",
    "        video_num_pop.append(str(i+1))\n",
    "    comments_pop.extend(comments_temp)\n",
    "    comment_id_pop.extend(comment_id_temp)\n",
    "    reply_count_pop.extend(reply_count_temp)\n",
    "    like_count_pop.extend(like_count_temp)\n",
    "    \n",
    "    video_id_pop.extend([video_id[i]]*len(comments_temp))\n",
    "    channel_pop.extend([channel[i]]*len(comments_temp))\n",
    "    video_title_pop.extend([video_title[i]]*len(comments_temp))\n",
    "    video_desc_pop.extend([video_desc[i]]*len(comments_temp))\n",
    "    \n",
    "# =============================================================================\n",
    "# Populate to Dataframe\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "\n",
    "output_dict_comments = {\n",
    "        'Query Num': query[0], #_pop_id,\n",
    "        'Query': query[1],\n",
    "        'Channel': channel_pop,\n",
    "        'Video Num': video_num_pop,\n",
    "        'Video ID': video_id_pop,\n",
    "        'Video Title': video_title_pop,\n",
    "        'Video Description': video_desc_pop,\n",
    "        'Comment': comments_pop,\n",
    "        'Comment ID': comment_id_pop,\n",
    "        'Replies': reply_count_pop,\n",
    "        'Likes': like_count_pop,\n",
    "        }\n",
    "\n",
    "output_df_comments = pd.DataFrame(output_dict_comments, columns = output_dict_comments.keys())\n",
    "# output comments to excel\n",
    "output_df_comments.to_excel(comments_file)\n",
    "print('Completed output file:', comments_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in analysis of excel files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
